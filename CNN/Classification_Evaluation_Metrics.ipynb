{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font color='blue'>Table of contents<\/font>\n",
                "\n",
                "- [Create the Model](#create-model)\n",
                "- [Generate Dataset](#data)\n",
                "- [Train the Model](#train)\n",
                "- [Confusion Matrix](#conf-mat)\n",
                "- [Accuracy](#accuracy)\n",
                "- [Precision](#precision)\n",
                "- [Recall \/ Sensitivity](#recall)\n",
                "- [F-1 Score](#F1-score)\n",
                "- [ROC Curve](#roc-curve)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">Classification Evaluation Metrics<\/font>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook will elaborate how to implement the different metrics in code. Most of these metrics are available in popular Machine Learning packages like Scikit-Learn etc. You need to develop a good  understanding of these metrics,for they play an important  role in  business decision-making.  Every data scientist or Machine Learning practitioner should know their significance and get familiar with their inner workings."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">1. Create the Model<\/font><a name=\"create-model\"><\/a>\n",
                "\n",
                "For the sake of simplicity, we will illustrate the performance metrics for the task of point classification to two classes: $\\{0, 1\\}$.\n",
                "\n",
                "\n",
                "Let's start by importing all the required packages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import matplotlib.pyplot as plt\n",
                "plt.style.use('ggplot')\n",
                "\n",
                "from sklearn.datasets import make_classification\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "plt.rcParams[\"figure.figsize\"] = (8, 8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">2. Generate Dataset<\/font><a name=\"data\"><\/a>\n",
                "\n",
                "The Scikit-Learn library provides a range of supervised as well as  standard  Machine Learning algorithms. [A blog on Introduction to Scikit-Learn](https:\/\/towardsdatascience.com\/an-introduction-to-scikit-learn-the-gold-standard-of-python-machine-learning-e2b9238a98ab). \n",
                "\n",
                "You start by creating a dataset. Use [make_classification](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.datasets.make_classification.html) function from the  scikit-learn library. It generates a random `n-class` classification problem, with normally-distributed clusters of points. Aso, add uniformly-distributed points, as noise to your data.\n",
                "\n",
                "For find more details on `sklearn.datasets.make_classification`, [click here](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.datasets.make_classification.html)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for reproducible results\n",
                "seed = 42  \n",
                "rng = np.random.RandomState(seed)\n",
                "torch.manual_seed(seed)\n",
                "\n",
                "\n",
                "# generate two class classification problem\n",
                "X, y = make_classification(\n",
                "    n_features=2, n_redundant=0, n_informative=2, random_state=seed, n_clusters_per_class=1\n",
                ")\n",
                "\n",
                "# add unifom random noise\n",
                "X += 4 * rng.uniform(size=X.shape)\n",
                "\n",
                "print('Inputs (X) shape: {}'.format(X.shape))\n",
                "print('Lables (y) shape: {}'.format(y.shape))\n",
                "\n",
                "plt.scatter(X[:,0],X[:,1],c=y,edgecolor='k')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">3. Train the Model<\/font><a name=\"train\"><\/a>\n",
                "\n",
                "Here, you train a [Logistic Regression](https:\/\/en.wikipedia.org\/wiki\/Logistic_regression) classifier. It  is equivalent to a one-layer neural network with sigmoid activation. You  have already implemented this using the basic functionality of PyTorch. But now, let's implement it again using PyTorch NN-module. \n",
                "\n",
                "We use sigmoid activation, so the model prediction will be prediction probability of class `1`.\n",
                "\n",
                "Ideally, you should create separate classes for different functionalities. For example, in this case, you have to train a model. There are  two parts: 1. Model, and 2. Training. Suppose we want to train different models to discover the best model for the dataset (a common practice in Machine Learning), it's a good idea to have a `trainer` class, which takes the `model` and `data`, and trains it.\n",
                "\n",
                "Let's start with this practice. Here, we will create two classes: `LogisticRegression` (model) and `Trainer`."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <font style=\"color:rgb(8,133,37)\">3.1. Create the Model Class<\/font>\n",
                "\n",
                "The `LogisticRegression` class  follows these methods:\n",
                "\n",
                "\n",
                "**`__init__`:**  It takes `n_features` (number of input data features) and initiates `nn-linear` function.\n",
                "\n",
                "**`forward`:** It takes `x` (data input) and does forward pass of the network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "class LogisticRegression(nn.Module):\n",
                "    def __init__(self, n_features):\n",
                "        super().__init__()\n",
                "        \n",
                "        # define linear layer (WX + B)\n",
                "        self.linear = nn.Linear(n_features, 1, bias=True)\n",
                "\n",
                "    def forward(self, x):\n",
                "        # calculate WX + B\n",
                "        x = self.linear(x)\n",
                "        \n",
                "        # sigmoid activation (prediction probability of class 1)\n",
                "        predictions = torch.sigmoid(x)\n",
                "        return predictions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <font style=\"color:rgb(8,133,37)\">3.2. Create the Trainer Class<\/font>\n",
                "\n",
                "Because PyTorch does not provide unified methods for training, we create a simple `Trainer` class to fit our model and make predictions.\n",
                "\n",
                "The **`Trainer` class follows these methods:**\n",
                "\n",
                "**`__init__`:** \n",
                "\n",
                "It takes three arguments.\n",
                "        \n",
                "- `model`: This has to be trained. Although we will pass the above-defined Linear Regression Model here, it can take any PyTorch model.\n",
                " \n",
                "- `criterion`: It  takes any NN-module loss function.\n",
                "        \n",
                "- `optimizer`: It takes the optimizer algorithm method.\n",
                "        \n",
                "- `epoch_num`: Number of epochs for training.\n",
                "\n",
                "**`fit`:** It takes two arguments, input and target.\n",
                "\n",
                "This method does the following:\n",
                "1. Forward pass of the `model`  with the `input`.\n",
                "\n",
                "1. Finds loss, using forward pass and `target`.\n",
                "\n",
                "1. Finds `gradient`, using `backprop`.\n",
                "\n",
                "1. Updates parameters using, `step`\n",
                "\n",
                "**`predict`:** It takes `input` as an argument. Only does forward pass and returns prediction.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "class Trainer:\n",
                "    def __init__(self, model, criterion, optimizer, epoch_num):\n",
                "        self.model = model\n",
                "        \n",
                "        # loss function\n",
                "        self.criterion = criterion\n",
                "        \n",
                "        # Optimizer\n",
                "        self.optimizer = optimizer\n",
                "        \n",
                "        # num of epochs\n",
                "        self.epoch_num = epoch_num\n",
                "\n",
                "    def fit(self, inputs, targets):\n",
                "        \"\"\"\n",
                "        Updating model trainable parameters in loop for given number of epochs\n",
                "        \"\"\"\n",
                "        \n",
                "        # set model in train state. \n",
                "        # Why this (and model.eval()) is important, \n",
                "        # we will see when we will train a deep neural network.\n",
                "        self.model.train()\n",
                "        \n",
                "        # run train loop for given epochs\n",
                "        for _ in range(self.epoch_num):\n",
                "            \n",
                "            # reset previously calculated gradient to zero\n",
                "            self.optimizer.zero_grad()\n",
                "            \n",
                "            # predict probability of class '1'\n",
                "            preds = self.model(inputs)\n",
                "            \n",
                "            # get loss\n",
                "            loss = self.criterion(preds, targets)\n",
                "            \n",
                "            # calculate gradients\n",
                "            loss.backward()\n",
                "            \n",
                "            # update parameters with gradient\n",
                "            self.optimizer.step()\n",
                "\n",
                "    def predict(self, inputs):\n",
                "        \n",
                "        # set model in train state. \n",
                "        self.model.eval()\n",
                "        # temporarily set requires_grad flag to false\n",
                "        with torch.no_grad():\n",
                "            # probability of class one prediction\n",
                "            preds = self.model(inputs)\n",
                "        return preds"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <font style=\"color:rgb(8,133,37)\">3.3. Training and Prediction<\/font>\n",
                "\n",
                "1. Divide the data into `train` (75%) and `test` data (25 %).\n",
                "\n",
                "2. Create a model object using `LogisticRegression` model class.\n",
                "\n",
                "3. Define `criterion` as binary cross-entropy loss.\n",
                "\n",
                "4. Define `optimizer` as `SGD` optimizer.\n",
                "\n",
                "5. Create the trainer object.\n",
                "\n",
                "6. Train the model using the `fit` method defined in `Trainer` class.\n",
                "\n",
                "7. Finally, get predictions for test data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Divide data into train (0.75) and test (0.25) set. \n",
                "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed)\n",
                "\n",
                "# train data from numpy to torch\n",
                "x_train, y_train = torch.from_numpy(x_train).float(), torch.from_numpy(y_train).float()\n",
                "\n",
                "# create model object\n",
                "log_regression = LogisticRegression(n_features=2)\n",
                "\n",
                "# define loss, in this case binary cross-entropy loss\n",
                "criterion = nn.BCELoss()\n",
                "\n",
                "# define optimizer, in this case Stochastic Gradient Descent  \n",
                "optimizer = torch.optim.SGD(log_regression.parameters(), lr=0.01)\n",
                "\n",
                "# create trainer object\n",
                "trainer = Trainer(log_regression, criterion, optimizer, 200)\n",
                "\n",
                "# train the model\n",
                "trainer.fit(x_train, y_train.unsqueeze(dim=1))\n",
                "\n",
                "# test data from numpy to torch\n",
                "x_test, y_test = torch.from_numpy(x_test).float(), torch.from_numpy(y_test).float()\n",
                "\n",
                "# probability of class one prediction\n",
                "y_predicted = trainer.predict(x_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">4. Confusion Matrix<\/font><a name=\"conf-mat\"><\/a>\n",
                "\n",
                "<img src=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2020\/01\/c3_w3_confusion_matrix.png\" width=600>\n",
                "\n",
                "Let's assume class `1` is a **`positive`** class, and class `0` is **`negative`** class.\n",
                "\n",
                "To get the confusion matrix and derive other methods from it, we implement the `ConfusionMatrix` class thus:\n",
                "\n",
                "\n",
                "**`__init__`:**  `self.conf` (confusion matrix variable) is initiated with `2x2` `ndarray`.\n",
                "\n",
                "**`reset`:** Reset `self.conf` to zero.\n",
                "\n",
                "**`add`:** It takes `pred` (prediction), and `target` (target label) to update `self.conf` .  Use `numpy.histogramdd` to get a multidimensional histogram. For more details about [click here](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.histogramdd.html). \n",
                "\n",
                "Let's see what happens in the implementation.\n",
                "\n",
                "`np.histogramdd(replace_indices, bins=(2, 2), range=[(0, 2), (0, 2)])`\n",
                "\n",
                "\n",
                "let's `replace_indices` is `7 x 2` `ndarray`, where Column `0` corresponds to `target` and column `1` corresponds to `prediction`.\n",
                "\n",
                "```\n",
                "replace_indices = [ [0, 1],\n",
                "                    [0, 0],\n",
                "                    [1, 1],\n",
                "                    [1, 1],\n",
                "                    [1, 0],\n",
                "                    [0, 1],\n",
                "                    [0, 0] ]\n",
                "```\n",
                "\n",
                "`bins=(2, 2)` means it will return `2 X 2` `ndarray`.\n",
                "\n",
                "`range=[(0, 2), (0, 2)])` means it will have the following bins:\n",
                "```\n",
                "[0, 0], [0, 1], [1, 0] and [1, 1]\n",
                "```\n",
                "\n",
                "So the following `ndarray` will return:\n",
                "```\n",
                "[[count_of([0, 0]), count_of([0, 1])],\n",
                " [count_of([1, 0]), count_of([1, 1])]] \n",
                "i.e.\n",
                "[[2, 2],\n",
                " [1, 2]]\n",
                "```\n",
                "\n",
                "Hence, `0` is the negative class, and `1` is the positive class:\n",
                "```\n",
                "count_of([1, 1]) = TP,\n",
                "count_of([0, 1]) = FP,\n",
                "count_of([0, 0]) = TN, and\n",
                "count_of([1, 0]) = FN\n",
                "```\n",
                "\n",
                "**`TP`:** Returns `true positive`\n",
                "\n",
                "**`FP`:** Returns `false positive`\n",
                "\n",
                "**`TN`:** Returns `true negative`\n",
                "\n",
                "**`FN`:** Returns `false negative`\n",
                "\n",
                "**`confusion_matrix`:** Returns confusion matrix:\n",
                "```\n",
                "[[TP, FP],\n",
                " [FN, TN]]\n",
                "```\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "class ConfusionMatrix:\n",
                "    def __init__(self):\n",
                "        # init confusion matrix\n",
                "        self.conf = np.ndarray((2, 2), np.int32)\n",
                "\n",
                "    def reset(self):\n",
                "        # reset to zero\n",
                "        self.conf.fill(0)\n",
                "\n",
                "    def add(self, pred, target):\n",
                "        \"\"\"\n",
                "        This will take predicted probability and True label and compute confusion matrix\n",
                "        \"\"\"\n",
                "        replace_indices = np.vstack((target.flatten(), pred.flatten())).T\n",
                "\n",
                "        conf, _ = np.histogramdd(replace_indices, bins=(2, 2), range=[(0, 2), (0, 2)])\n",
                "\n",
                "        self.conf += conf.astype(np.int32)\n",
                "\n",
                "    def TP(self):\n",
                "        return self.conf[1,1]\n",
                "    \n",
                "    def FP(self):\n",
                "        return self.conf[0, 1]\n",
                "    \n",
                "    def TN(self):\n",
                "        return self.conf[0, 0]\n",
                "    \n",
                "    def FN(self):\n",
                "        return self.conf[1, 0]\n",
                "    \n",
                "    def confusion_matrix(self):\n",
                "        \"\"\"\n",
                "        get confusion matrix as defined in figure\n",
                "        \"\"\"\n",
                "        cm = np.array([[self.TP(), self.FP()],\n",
                "                      [self.FN(), self.TN()]])\n",
                "        return cm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's compute the confusion matrix for threshold probability `0.5` and `0.7`.\n",
                "\n",
                "Follow these steps:\n",
                "\n",
                "\n",
                "1. Init the `ConfusionMatrix` class.\n",
                "1. Get `prediction` by using`y_predicted` and `threshold probability` .\n",
                "1. Reset the confusion matrix.\n",
                "1. Compute confusion matrix using `add`.\n",
                "1. Call `confusion_matrix()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# threshold probability 0.5\n",
                "\n",
                "cm = ConfusionMatrix()\n",
                "\n",
                "thres_prob = 0.5\n",
                "predictions = y_predicted > thres_prob\n",
                "\n",
                "# reset confusion matrix\n",
                "cm.reset()\n",
                "\n",
                "# compute confusion matrix\n",
                "cm.add(predictions, y_test)\n",
                "\n",
                "\n",
                "print('Confusion Matrix for threshold probability 0.5:\\n{}'.format(cm.confusion_matrix()))\n",
                "\n",
                "\n",
                "thres_prob = 0.6\n",
                "predictions = y_predicted > thres_prob\n",
                "\n",
                "# reset confusion matrix\n",
                "cm.reset()\n",
                "\n",
                "# compute confusion matrix\n",
                "cm.add(predictions, y_test)\n",
                "\n",
                "\n",
                "print('Confusion Matrix for threshold probability 0.6:\\n{}'.format(cm.confusion_matrix()))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">5. Accuracy<\/font><a name=\"accuracy\"><\/a>\n",
                "\n",
                "<img src=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2020\/01\/c3_w3_accuracy.png\" width=600>\n",
                "\n",
                "$$\n",
                "accuracy = \\frac{TP + TN}{TF + FP + FN + TN }\n",
                "$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def accuracy(thres_prob, y_predicted, y_true):\n",
                "    predictions = y_predicted > thres_prob\n",
                "\n",
                "    # reset confusion matrix\n",
                "    cm.reset()\n",
                "    # compute confusion matrix\n",
                "    cm.add(predictions, y_true)\n",
                "    \n",
                "    # accuracy \n",
                "    acc = (cm.TP() + cm.TN())\/(cm.TP() + cm.FP() + cm.FN() + cm.TN())\n",
                "    \n",
                "    return acc\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "acc = accuracy(0.5, y_predicted, y_test)\n",
                "\n",
                "print('Accuracy at threshold 0.5: {}'.format(acc))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">6. Precision<\/font><a name=\"precision\"><\/a>\n",
                "\n",
                "<img src=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2020\/01\/c3_w3_precision.png\" width=600>\n",
                "\n",
                "$$\n",
                "precision = \\frac{TP}{TP + FP}\n",
                "$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def precision(thres_prob, y_predicted, y_true):\n",
                "    predictions = y_predicted > thres_prob\n",
                "\n",
                "    # reset confusion matrix\n",
                "    cm.reset()\n",
                "    # compute confusion matrix\n",
                "    cm.add(predictions, y_true)\n",
                "    \n",
                "    # precision\n",
                "    pre = cm.TP()\/(cm.TP() + cm.FP())\n",
                "    \n",
                "    return pre"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "pre = precision(0.5, y_predicted, y_test)\n",
                "\n",
                "print('Precision at threshold 0.5: {0:.3}'.format(pre))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">7. Recall \/ Sensitivity<\/font><a name=\"recall\"><\/a>\n",
                "\n",
                "<img src='https:\/\/www.learnopencv.com\/wp-content\/uploads\/2020\/01\/c3_w3_recall.png' width=600>\n",
                "\n",
                "$$\n",
                "recall = \\frac{TP}{TP + FN}\n",
                "$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def recall(thres_prob, y_predicted, y_true):\n",
                "    predictions = y_predicted > thres_prob\n",
                "\n",
                "    # reset confusion matrix\n",
                "    cm.reset()\n",
                "    # compute confusion matrix\n",
                "    cm.add(predictions, y_true)\n",
                "    \n",
                "    # recall\n",
                "    rec = cm.TP()\/(cm.TP() + cm.FN())\n",
                "    \n",
                "    return rec\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "rec = recall(0.5, y_predicted, y_test)\n",
                "\n",
                "print('Recall at threshold 0.5: {0:.3}'.format(rec))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">8. F-1 Score<\/font><a name=\"F1-score\"><\/a>\n",
                "\n",
                "$$\n",
                "F_1 score = \\frac{2 TP}{2TP + FP + FN}\n",
                "$$\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def f1_score(thres_prob, y_predicted, y_true):\n",
                "    predictions = y_predicted > thres_prob\n",
                "\n",
                "    # reset confusion matrix\n",
                "    cm.reset()\n",
                "    # compute confusion matrix\n",
                "    cm.add(predictions, y_true)\n",
                "    \n",
                "    # f1 score\n",
                "    score = (2*cm.TP())\/(2*cm.TP() + cm.FP() + cm.FN())\n",
                "    \n",
                "    return score\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "f1_score = f1_score(0.5, y_predicted, y_test)\n",
                "\n",
                "print('F1 score at threshold 0.5: {}'.format(f1_score))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">9. ROC Curve<\/font><a name=\"roc-curve\"><\/a>\n",
                "\n",
                "<img src=\"https:\/\/www.learnopencv.com\/wp-content\/uploads\/2020\/01\/c3_w3_roc.png\" width=700>\n",
                "\n",
                "\n",
                "\\begin{align}\n",
                "TPR (recall) &= \\frac{TP}{TP + FN} \\\\\n",
                "FPR &= \\frac{FP}{FP + TN} \\\\\n",
                "\\end{align}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <font style=\"color:rgb(8,133,37)\">9.1. ROC Curve Using Confusion Matrix<\/font>\n",
                "\n",
                "For `threshold_probability` in `[0, 1]`:\n",
                "1. By using `ConfusionMatrix` class get `TP` (true positive), `FP` (false positive), `FN` (false negative), and `TN` (true negative).\n",
                "\n",
                "2. Calculate `TPR` (true positive rate) and `FPR` (false positive rate).\n",
                "\n",
                "Plot `TPR-vs-FPR`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "thresholds = np.linspace(0.001, 0.999, 1000)\n",
                "\n",
                "tp_rates = []\n",
                "fp_rates = []\n",
                "cm = ConfusionMatrix()\n",
                "\n",
                "for threshold in thresholds:\n",
                "\n",
                "    # get prediction\n",
                "    predictions = y_predicted > threshold\n",
                "    \n",
                "    # rest confusion matrix\n",
                "    cm.reset()\n",
                "    \n",
                "    # calculate confusion matrix\n",
                "    cm.add(predictions, y_test)\n",
                "    \n",
                "    # get TP, FP, FN, and TN to calculate TPR and FPR\n",
                "    TN = cm.TN()\n",
                "    FP = cm.FP()\n",
                "    FN = cm.FN()\n",
                "    TP = cm.TP()\n",
                "\n",
                "    # Sensitivity, recall, or true positive rate\n",
                "    TPR = TP \/ (TP + FN)\n",
                "    tp_rates.append(TPR)\n",
                "\n",
                "    # False positive rate\n",
                "    FPR = FP \/ (FP + TN)\n",
                "    fp_rates.append(FPR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Let's plot `true positive rate` vs `false positive rate`.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(fp_rates, tp_rates, label='ROC curve', color='b')\n",
                "plt.plot([0, 1], [0, 1], label='Random Classifier (AUC = 0.5)', linestyle='--', lw=2, color='r')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.legend(loc=\"lower right\")\n",
                "plt.title('ROC Curve')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <font style=\"color:rgb(8,133,37)\">9.2. ROC Curve Using Definition & AUC<\/font>\n",
                "\n",
                "To plot the ROC Curve and calculate the ROC AUC Score, let's create a class `ROCCurve`. This approach suses the [False Positive](https:\/\/en.wikipedia.org\/wiki\/False_positive_rate)  and True [True Positive](https:\/\/en.wikipedia.org\/wiki\/Sensitivity_and_specificity#Sensitivity) to build the ROC Curve.\n",
                "\n",
                "By increasing the threshold between two classes and calculating a number of `true positives`, `true negatives`, `false positives` and `false negatives` for each of them, we can get a set of corresponding `true positive rate` and `false positive rates`.\n",
                "\n",
                "\n",
                "Let us also write an `ROCCurve` class and follow its methods to plot the ROC curve and calculate AUC. Check out  all the methods:\n",
                "\n",
                "\n",
                "**`__init__`:** It takes `y_test` and `y_pred_score` as arguments and initiate attributes `y_test` and `y_pred_score` respectively. \n",
                "\n",
                "**`_get_fpr_tpr`:** returns `FPR` and `TPR` for a range of thresholds.\n",
                "\n",
                "**`_get_tp_fp_tn_fn`:** returns `TP`, `FP`, `TN`, and `FN` for a range of threshold.\n",
                "\n",
                "**`plot_roc`:** get `TPR` and `FPR` from `_get_fpr_tpr` and plot `TPR`-vs-`FPR` (ROC Curve).\n",
                "\n",
                "**`get_auc_score`:** get `TPR` and `FPR` from `_get_fpr_tpr` and calculate `AUC`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "class ROCCurve:\n",
                "    def __init__(self, y_test, y_pred_score):\n",
                "        # Init attributes \n",
                "        self.y_test = y_test\n",
                "        self.y_pred_score = y_pred_score\n",
                "\n",
                "    def _get_fpr_tpr(self):\n",
                "        # thresholds\n",
                "        thresholds = torch.linspace(0.001, 0.999, 1000).unsqueeze(1)\n",
                "        \n",
                "        # get prediction for all thresholds\n",
                "        self.y_pred = self.y_pred_score.T > thresholds\n",
                "        \n",
                "        # get TP, FP, TN, and FN for all thresholds\n",
                "        tp, fp, tn, fn = self._get_tp_fp_tn_fn()\n",
                "        \n",
                "        # calculate true positive rate for all thresholds\n",
                "        tpr = tp.float() \/ (tp + fn)\n",
                "        \n",
                "        # calculate false positive rate for all thresholds\n",
                "        fpr = fp.float() \/ (fp + tn)\n",
                "        \n",
                "        return fpr.flip((0, )), tpr.flip((0, ))\n",
                "        \n",
                "\n",
                "    def _get_tp_fp_tn_fn(self):\n",
                "        \n",
                "        # change datatype to bool\n",
                "        self.y_pred = self.y_pred.bool()\n",
                "        self.y_test = self.y_test.bool()\n",
                "        \n",
                "        # calculate TP\n",
                "        tp = (self.y_pred & self.y_test).sum(dim=1)\n",
                "        \n",
                "        # calculate FP\n",
                "        fp = (self.y_pred & ~self.y_test).sum(dim=1)\n",
                "        \n",
                "        # calculate TN\n",
                "        tn = (~self.y_pred & ~self.y_test).sum(dim=1)\n",
                "        \n",
                "        # calculate FN\n",
                "        fn = (~self.y_pred & self.y_test).sum(dim=1)\n",
                "        \n",
                "        return tp, fp, tn, fn\n",
                "\n",
                "    def plot_roc(self):\n",
                "        \n",
                "        # get TPR and FPR and plot TPR-vs-FPR\n",
                "        plt.plot(*self._get_fpr_tpr(), label='ROC curve', color='g')\n",
                "        plt.plot([0, 1], [0, 1], label='Random Classifier (AUC = 0.5)', linestyle='--', lw=2, color='r')\n",
                "        plt.xlabel('False Positive Rate')\n",
                "        plt.ylabel('True Positive Rate')\n",
                "        plt.legend(loc=\"lower right\")\n",
                "        plt.title('ROC Curve')\n",
                "        plt.show()\n",
                "\n",
                "    def get_auc_score(self):\n",
                "        # Get TPR and FPR\n",
                "        fpr, tpr = self._get_fpr_tpr()\n",
                "        \n",
                "        # get area under the curve of TPR-vs-FPR plot\n",
                "        return np.trapz(tpr, fpr), fpr, tpr"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Now we can use an object of our class to plot the ROC curve**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "roc_auc = ROCCurve(y_test, y_predicted)\n",
                "roc_auc.plot_roc()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Also, we implemented the function to calculate the area under the ROC curve.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "roc_auc_score, fpr, tpr = roc_auc.get_auc_score()\n",
                "print('ROC AUC Score: {0:.3}'.format(roc_auc_score))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python38"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}