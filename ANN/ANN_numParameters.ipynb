{"cells":[{"cell_type":"markdown","metadata":{"id":"bhWV8oes-wKR"},"source":["## SECTION: ANNs\n","### LECTURE: Depth vs. breadth: number of parameters"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"j7-LiwqUMGYL"},"outputs":[],"source":["# import libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"krQeh5wYMNla"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Linear(in_features=2, out_features=4, bias=True)\n","  (1): Linear(in_features=4, out_features=3, bias=True)\n",")\n"," \n","Sequential(\n","  (0): Linear(in_features=2, out_features=2, bias=True)\n","  (1): Linear(in_features=2, out_features=2, bias=True)\n","  (2): Linear(in_features=2, out_features=3, bias=True)\n",")\n"]}],"source":["# build two models\n","\n","widenet = nn.Sequential(\n","    nn.Linear(2,4),  # hidden layer\n","    nn.Linear(4,3),  # output layer\n","    )\n","\n","\n","deepnet = nn.Sequential(\n","    nn.Linear(2,2),  # hidden layer\n","    nn.Linear(2,2),  # hidden layer\n","    nn.Linear(2,3),  # output layer\n","    )\n","\n","# print them out to have a look\n","print(widenet)\n","print(' ')\n","print(deepnet)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Rv5g3ISypDNk"},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=2, out_features=4, bias=True)\n","  (1): Linear(in_features=4, out_features=3, bias=True)\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["widenet"]},{"cell_type":"markdown","metadata":{"id":"ni8L4jRgopMO"},"source":["# Peeking inside the network"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"lrKmii4Xmx-Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["('0.weight', Parameter containing:\n","tensor([[-0.6875, -0.1674],\n","        [-0.1307, -0.5258]], requires_grad=True))\n"," \n","('0.bias', Parameter containing:\n","tensor([-0.3904,  0.3138], requires_grad=True))\n"," \n","('1.weight', Parameter containing:\n","tensor([[ 0.0024,  0.5044],\n","        [ 0.3151, -0.2269]], requires_grad=True))\n"," \n","('1.bias', Parameter containing:\n","tensor([-0.5999, -0.0134], requires_grad=True))\n"," \n","('2.weight', Parameter containing:\n","tensor([[-0.2010,  0.5325],\n","        [ 0.3552, -0.2665],\n","        [ 0.4921,  0.3146]], requires_grad=True))\n"," \n","('2.bias', Parameter containing:\n","tensor([-0.0138,  0.6397,  0.1466], requires_grad=True))\n"," \n"]}],"source":["# check out the parameters\n","for p in deepnet.named_parameters():\n","  print(p)\n","  print(' ')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"I811amwtouaY"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 7 nodes in the wide network.\n","There are 7 nodes in the deep network.\n"]}],"source":["# count the number of nodes ( = the number of biases)\n","\n","# named_parameters() is an iterable that returns the tuple (name,numbers)\n","numNodesInWide = 0\n","for p in widenet.named_parameters():\n","  if 'bias' in p[0]:\n","    numNodesInWide += len(p[1])\n","\n","numNodesInDeep = 0\n","for paramName,paramVect in deepnet.named_parameters():\n","  if 'bias' in paramName:\n","    numNodesInDeep += len(paramVect)\n","\n","\n","print('There are %s nodes in the wide network.' %numNodesInWide)\n","print('There are %s nodes in the deep network.' %numNodesInDeep)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"FVuYUMy7spW9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[ 0.1020,  0.5469],\n","        [-0.5919,  0.0396],\n","        [ 0.4953,  0.5556],\n","        [ 0.1223,  0.1620]], requires_grad=True)\n"," \n","Parameter containing:\n","tensor([-0.0073,  0.5460,  0.5859,  0.4123], requires_grad=True)\n"," \n","Parameter containing:\n","tensor([[-0.0145,  0.3493,  0.1455,  0.2941],\n","        [-0.0347,  0.1136,  0.2889, -0.0966],\n","        [ 0.3975,  0.4907, -0.2011, -0.3831]], requires_grad=True)\n"," \n","Parameter containing:\n","tensor([ 0.4323,  0.3174, -0.4572], requires_grad=True)\n"," \n"]}],"source":["# just the parameters\n","for p in widenet.parameters():\n","  print(p)\n","  print(' ')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"xtTwxsVhirEq"},"outputs":[{"name":"stdout","output_type":"stream","text":["This piece has 8 parameters\n","This piece has 4 parameters\n","This piece has 12 parameters\n","This piece has 3 parameters\n","\n","\n","Total of 27 parameters\n"]}],"source":["# now count the total number of trainable parameters\n","nparams = 0\n","for p in widenet.parameters():\n","  if p.requires_grad:\n","    print('This piece has %s parameters' %p.numel())\n","    nparams += p.numel()\n","\n","print('\\n\\nTotal of %s parameters'%nparams)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"PKr2ARdWivz8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Widenet has 27 parameters\n","Deepnet has 21 parameters\n"]}],"source":["# btw, can also use list comprehension\n","\n","nparams = np.sum([ p.numel() for p in widenet.parameters() if p.requires_grad ])\n","print('Widenet has %s parameters'%nparams)\n","\n","nparams = np.sum([ p.numel() for p in deepnet.parameters() if p.requires_grad ])\n","print('Deepnet has %s parameters'%nparams)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I9wsTcbrrYT7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_6GzhyxLUrYy"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                 [-1, 1, 4]              12\n","            Linear-2                 [-1, 1, 3]              15\n","================================================================\n","Total params: 27\n","Trainable params: 27\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","----------------------------------------------------------------\n"]}],"source":["# A nice simple way to print out the model info.\n","from torchsummary import summary\n","summary(widenet,(1,2))\n","\n","\n","### NOTE ABOUT THE CODE IN THIS CELL:\n","# torchsummary is being replaced by torchinfo.\n","# If you are importing these libraries on your own (via pip), then see the following website:\n","#        https://pypi.org/project/torch-summary/\n","# However, torchsummary will continue to be supported, so if the code in this cell works (meaning torchsummary is already installed), \n","# then you don't need to do anything!"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                 [-1, 1, 4]              12\n","            Linear-2                 [-1, 1, 3]              15\n","================================================================\n","Total params: 27\n","Trainable params: 27\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","----------------------------------------------------------------\n"]}],"source":["# A nice simple way to print out the model info.\n","from torchsummary import summary\n","summary(widenet,(1,2))\n","\n","\n","### NOTE ABOUT THE CODE IN THIS CELL:\n","# torchsummary is being replaced by torchinfo.\n","# If you are importing these libraries on your own (via pip), then see the following website:\n","#        https://pypi.org/project/torch-summary/\n","# However, torchsummary will continue to be supported, so if the code in this cell works (meaning torchsummary is already installed), \n","# then you don't need to do anything!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHlWL3_drYhT"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNp0/OYNZqgbUCz8Xrl2dyW","collapsed_sections":[],"name":"DUDL_ANN_numParameters.ipynb","provenance":[{"file_id":"1Q_oDw0aMA4QFKDnLxuqJp62P8oPMtO1R","timestamp":1618255245074},{"file_id":"1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD","timestamp":1615884593383}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
